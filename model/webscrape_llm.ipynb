{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting requests\n",
      "  Using cached requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests)\n",
      "  Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl.metadata (36 kB)\n",
      "Collecting idna<4,>=2.5 (from requests)\n",
      "  Using cached idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests)\n",
      "  Using cached urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests)\n",
      "  Using cached certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
      "Using cached requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
      "Using cached charset_normalizer-3.4.1-cp313-cp313-win_amd64.whl (102 kB)\n",
      "Using cached idna-3.10-py3-none-any.whl (70 kB)\n",
      "Using cached urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
      "Installing collected packages: urllib3, idna, charset-normalizer, certifi, requests\n",
      "Successfully installed certifi-2025.1.31 charset-normalizer-3.4.1 idna-3.10 requests-2.32.3 urllib3-2.3.0\n",
      "Collecting beautifulsoup4\n",
      "  Using cached beautifulsoup4-4.13.3-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting soupsieve>1.2 (from beautifulsoup4)\n",
      "  Using cached soupsieve-2.6-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting typing-extensions>=4.0.0 (from beautifulsoup4)\n",
      "  Using cached typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
      "Using cached beautifulsoup4-4.13.3-py3-none-any.whl (186 kB)\n",
      "Using cached soupsieve-2.6-py3-none-any.whl (36 kB)\n",
      "Using cached typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
      "Installing collected packages: typing-extensions, soupsieve, beautifulsoup4\n",
      "Successfully installed beautifulsoup4-4.13.3 soupsieve-2.6 typing-extensions-4.12.2\n",
      "Collecting langchain-community\n",
      "  Using cached langchain_community-0.3.20-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting langchain-core<1.0.0,>=0.3.45 (from langchain-community)\n",
      "  Using cached langchain_core-0.3.48-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.21 (from langchain-community)\n",
      "  Using cached langchain-0.3.21-py3-none-any.whl.metadata (7.8 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain-community)\n",
      "  Downloading sqlalchemy-2.0.39-cp313-cp313-win_amd64.whl.metadata (9.9 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\.venv\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Collecting PyYAML>=5.3 (from langchain-community)\n",
      "  Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain-community)\n",
      "  Downloading aiohttp-3.11.14-cp313-cp313-win_amd64.whl.metadata (8.0 kB)\n",
      "Collecting tenacity!=8.4.0,<10,>=8.1.0 (from langchain-community)\n",
      "  Downloading tenacity-9.0.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.8.1-py3-none-any.whl.metadata (3.5 kB)\n",
      "Collecting langsmith<0.4,>=0.1.125 (from langchain-community)\n",
      "  Using cached langsmith-0.3.18-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\n",
      "Collecting numpy<3,>=1.26.2 (from langchain-community)\n",
      "  Downloading numpy-2.2.4-cp313-cp313-win_amd64.whl.metadata (60 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl.metadata (5.9 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading aiosignal-1.3.2-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading frozenlist-1.5.0-cp313-cp313-win_amd64.whl.metadata (14 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading multidict-6.2.0-cp313-cp313-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting propcache>=0.2.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading propcache-0.3.0-cp313-cp313-win_amd64.whl.metadata (10 kB)\n",
      "Collecting yarl<2.0,>=1.17.0 (from aiohttp<4.0.0,>=3.8.3->langchain-community)\n",
      "  Downloading yarl-1.18.3-cp313-cp313-win_amd64.whl.metadata (71 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl.metadata (7.3 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.7 (from langchain<1.0.0,>=0.3.21->langchain-community)\n",
      "  Using cached langchain_text_splitters-0.3.7-py3-none-any.whl.metadata (1.9 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain<1.0.0,>=0.3.21->langchain-community)\n",
      "  Using cached pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<1.0.0,>=0.3.45->langchain-community)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-community) (4.12.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain-community)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.4,>=0.1.125->langchain-community)\n",
      "  Downloading orjson-3.10.16-cp313-cp313-win_amd64.whl.metadata (42 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.4,>=0.1.125->langchain-community)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting zstandard<0.24.0,>=0.23.0 (from langsmith<0.4,>=0.1.125->langchain-community)\n",
      "  Downloading zstandard-0.23.0-cp313-cp313-win_amd64.whl.metadata (3.0 kB)\n",
      "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langchain-community) (2025.1.31)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain-community)\n",
      "  Downloading greenlet-3.1.1-cp313-cp313-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community)\n",
      "  Using cached anyio-4.9.0-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community)\n",
      "  Using cached httpcore-1.0.7-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community)\n",
      "  Using cached h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-community)\n",
      "  Using cached jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.27.2 (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain-community)\n",
      "  Downloading pydantic_core-2.27.2-cp313-cp313-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting sniffio>=1.1 (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-community)\n",
      "  Using cached sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Using cached langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
      "Downloading aiohttp-3.11.14-cp313-cp313-win_amd64.whl (436 kB)\n",
      "Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Using cached langchain-0.3.21-py3-none-any.whl (1.0 MB)\n",
      "Using cached langchain_core-0.3.48-py3-none-any.whl (418 kB)\n",
      "Using cached langsmith-0.3.18-py3-none-any.whl (351 kB)\n",
      "Downloading numpy-2.2.4-cp313-cp313-win_amd64.whl (12.6 MB)\n",
      "   ---------------------------------------- 0.0/12.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/12.6 MB 5.0 MB/s eta 0:00:03\n",
      "   ------ --------------------------------- 2.1/12.6 MB 5.3 MB/s eta 0:00:03\n",
      "   --------- ------------------------------ 3.1/12.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ------------- -------------------------- 4.2/12.6 MB 5.5 MB/s eta 0:00:02\n",
      "   ---------------- ----------------------- 5.2/12.6 MB 5.4 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 6.3/12.6 MB 5.2 MB/s eta 0:00:02\n",
      "   ---------------------- ----------------- 7.1/12.6 MB 4.9 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 8.4/12.6 MB 5.1 MB/s eta 0:00:01\n",
      "   ------------------------------ --------- 9.7/12.6 MB 5.3 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 11.0/12.6 MB 5.3 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 12.1/12.6 MB 5.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 12.6/12.6 MB 5.4 MB/s eta 0:00:00\n",
      "Downloading pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Using cached PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)\n",
      "Downloading sqlalchemy-2.0.39-cp313-cp313-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   -------------- ------------------------- 0.8/2.1 MB 4.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.1 MB 4.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 4.0 MB/s eta 0:00:00\n",
      "Downloading tenacity-9.0.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Downloading aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Downloading frozenlist-1.5.0-cp313-cp313-win_amd64.whl (51 kB)\n",
      "Downloading greenlet-3.1.1-cp313-cp313-win_amd64.whl (299 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.7-py3-none-any.whl (78 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Using cached langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
      "Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Downloading multidict-6.2.0-cp313-cp313-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.16-cp313-cp313-win_amd64.whl (133 kB)\n",
      "Downloading propcache-0.3.0-cp313-cp313-win_amd64.whl (43 kB)\n",
      "Using cached pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
      "Downloading pydantic_core-2.27.2-cp313-cp313-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   --------------------- ------------------ 1.0/2.0 MB 6.1 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 1.3/2.0 MB 2.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 3.5 MB/s eta 0:00:00\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading yarl-1.18.3-cp313-cp313-win_amd64.whl (315 kB)\n",
      "Downloading zstandard-0.23.0-cp313-cp313-win_amd64.whl (495 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Using cached anyio-4.9.0-py3-none-any.whl (100 kB)\n",
      "Using cached h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Using cached sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zstandard, tenacity, sniffio, PyYAML, python-dotenv, pydantic-core, propcache, orjson, numpy, mypy-extensions, multidict, marshmallow, jsonpointer, httpx-sse, h11, greenlet, frozenlist, attrs, annotated-types, aiohappyeyeballs, yarl, typing-inspect, SQLAlchemy, requests-toolbelt, pydantic, jsonpatch, httpcore, anyio, aiosignal, pydantic-settings, httpx, dataclasses-json, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain, langchain-community\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.39 aiohappyeyeballs-2.6.1 aiohttp-3.11.14 aiosignal-1.3.2 annotated-types-0.7.0 anyio-4.9.0 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.5.0 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.7 httpx-0.28.1 httpx-sse-0.4.0 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.21 langchain-community-0.3.20 langchain-core-0.3.48 langchain-text-splitters-0.3.7 langsmith-0.3.18 marshmallow-3.26.1 multidict-6.2.0 mypy-extensions-1.0.0 numpy-2.2.4 orjson-3.10.16 propcache-0.3.0 pydantic-2.10.6 pydantic-core-2.27.2 pydantic-settings-2.8.1 python-dotenv-1.0.1 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-9.0.0 typing-inspect-0.9.0 yarl-1.18.3 zstandard-0.23.0\n"
     ]
    }
   ],
   "source": [
    "!pip install requests\n",
    "!pip install beautifulsoup4\n",
    "!pip install langchain-community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'https://pythonology.eu/using-pandas_ta-to-generate-technical-indicators-and-signals/', 'title': 'Previous'}, page_content=\"Disclaimer:Remember that trading involves risk, and most traders lose money. This blog post is for educational purposes only. Always practice risk management and consider seeking professional advice before trading.Table of ContentsDisclaimer:What Is Algorithmic Trading? Advantages of Algorithmic TradingDisadvantages of Algorithmic TradingUsing Python for Algorithmic TradingTechnical Analysis with PythonPlotting Simple Moving Averages (SMA)Plotting RSIA Simple Trading StrategyConclusionWhat Is Algorithmic Trading?Algorithmic trading, often referred to as algo trading, uses computer algorithms to automate trading decisions based on predefined criteria. These criteria are set by the traders, for example, you might tell the program to Buy when the last 5 candlesticks have an upward trend, or Sell when the last 5 candlesticks are following a downtrend. This approach eliminates human emotions, enabling data-driven decision-making and executing trades at high speed and precision.This approach, however, has some advantages and disadvantages.Advantages of Algorithmic TradingReduced Emotional Bias: Automated systems execute trades based on logic, not emotions.Faster Execution: Algorithms can process vast amounts of data and execute orders in milliseconds.Scalability: Algorithms can manage multiple trading strategies and assets simultaneously.Disadvantages of Algorithmic TradingTechnical Glitches: Systems can fail due to bugs or connectivity issues.Over-Optimization: Strategies may be overly fine-tuned to historical data, reducing real-world performance.Market Volatility: Sudden market changes can lead to significant losses.Using Python for Algorithmic TradingPython is a popular language for algorithmic trading due to its simplicity and extensive libraries. There are a lot of great libraries which are used for collecting trading data, processing and plotting the data, and generating technical indicators. In order to analyze the market and understand the trend and find opportunities to trade, we can use the historical data provided by Yahoo and the yfinance library (pip install yfinance):import yfinance as yf\\n\\n# Fetch historical data for EUR/USD\\ndata = yf.download('EURUSD=X', start='2023-10-01', end='2024-07-10', interval='1d')\\n\\n# Check the first 5 rows of data\\nprint(data.head())Technical Analysis with PythonLibraries like pandas and numpy are essential for data manipulation. For technical analysis, I recommend pandas_ta technical analysis library.I am going to explain how you can use the pandas_ta library to plot simple indicators such as Simple Moving Average and RSI and then generate Buy and Sell signals.Plotting Simple Moving Averages (SMA)Simple Moving Average is the “Hello World” of algorithmic trading. It is very easy to calculate and plot. It shows the trend of the market by calculating the average price of an asset over a specified period, typically using closing prices.Here’s how to calculate and plot SMA:# remember to install pandas and pandas_ta\\n# we use the data we just downloaded by yfinance\\n\\nimport pandas as pd\\nimport matplotlib.pyplot as plt\\nimport pandas_ta as ta\\n\\n# Calculate SMAs and add them to the data as columns\\ndata['SMA_20'] = ta.sma(data['Close'], length=20)\\ndata['SMA_50'] = ta.sma(data['Close'], length=50)\\n\\n# Plotting SMAs\\nplt.figure(figsize=(12, 6))\\nplt.plot(data['Close'], label='Close Price')\\nplt.plot(data['SMA_20'], label='20-Day SMA')\\nplt.plot(data['SMA_50'], label='50-Day SMA')\\nplt.legend()\\nplt.show()\\nAs you saw in the code we used the following code to calculate the SMA of the last 20 days and then added the results as a column to our data dataframe:ta.sma(data['Close'], length=20)If you want to know which methods are available through pandas_ta on your data, you can use the help function:help(data.ta)Plotting RSIThe Relative Strength Index (RSI) is a momentum oscillator that measures the speed and change of price movements. It oscillates between 0 and 100 and is typically used to identify overbought (above 70) or oversold (below 30) conditions in a market.Here’s how you can calculate and plot RSI using pandas_ta:# we are using the same data as before\\n# Calculate RSI\\ndata['RSI'] = ta.rsi(data['Close'], length=14)\\n\\n# Plotting RSI\\nplt.figure(figsize=(12, 6))\\nplt.plot(data['RSI'], label='RSI')\\nplt.axhline(30, linestyle='--', alpha=0.5, color='red')\\nplt.axhline(70, linestyle='--', alpha=0.5, color='red')\\nplt.title('RSI')\\nplt.legend()\\nplt.show()A Simple Trading StrategyHere is a simple trading strategy using SMA.Buy SignalWhen the short-term SMA crosses above the long-term SMA.Sell SignalWhen the short-term SMA crosses below the long-term SMA.We’ll generate buy and sell signals based on the crossover of a short-term SMA and a long-term SMA, and plot these signals on the chart in green and red.# use the same data as before\\n# Calculate indicators\\ndata['SMA_50'] = ta.sma(data['Close'], length=50)\\ndata['SMA_200'] = ta.sma(data['Close'], length=200)\\n\\n# Generate Buy and Sell signals\\ndata['Buy_Signal'] = np.where((data['SMA_50'] > data['SMA_200']) & (data['SMA_50'].shift(1) <= data['SMA_200'].shift(1)), 1, 0)\\ndata['Sell_Signal'] = np.where((data['SMA_50'] < data['SMA_200']) & (data['SMA_50'].shift(1) >= data['SMA_200'].shift(1)), -1, 0)\\n\\n# Plotting\\nplt.figure(figsize=(14, 8))\\n\\n# Plot Closing Price and SMAs\\nplt.plot(data['Close'], label='Close Price', alpha=0.5)\\nplt.plot(data['SMA_50'], label='50-Day SMA', alpha=0.75, color='blue')\\nplt.plot(data['SMA_200'], label='200-Day SMA', alpha=0.75, color='orange')\\n\\n# Plot Buy Signals\\nplt.plot(data[data['Buy_Signal'] == 1].index, data['Close'][data['Buy_Signal'] == 1], '^', markersize=10, color='g', lw=0, label='Buy Signal')\\n\\n# Plot Sell Signals\\nplt.plot(data[data['Sell_Signal'] == -1].index, data['Close'][data['Sell_Signal'] == -1], 'v', markersize=10, color='r', lw=0, label='Sell Signal')\\n\\nplt.title('EUR/USD Price with SMA Crossover Buy and Sell Signals')\\nplt.legend()\\nplt.show()Summary of strategy:Data Fetching: We use yfinance to download historical data for EUR/USD.Indicator Calculation: We calculate the 50-day and 200-day SMAs using pandas-ta.Signal Generation: Buy signals are generated when the 50-day SMA crosses above the 200-day SMA, and sell signals are generated when the 50-day SMA crosses below the 200-day SMA.Plotting: We plot the closing price and the SMAs as line charts. Buy signals are marked with green triangles, and sell signals are marked with red triangles.As you can see this strategy does not predict the trend well. So you need to consider other ways to generate signals.ConclusionIn this post, I have introduced you to the pandas_ta python library for trading technical analysis to generate technical indicators and buy/sell signals. Algorithmic trading is a very complex field and requires a lot of knowledge regarding not only finance and market analysis, but also programming. You do not want to rely on these simple strategies to risk your money! Trading requires knowledge of risk and emotion management. So, this post was just an introduction to how you can start to learn a useful library and hopefully improve your knowledge of algorithmic trading.\\n\\nvahidI hold a PhD in Applied Linguistics. My passion for natural languages drew me toward NLP and learning Python. Now, I run a Youtube channel called Pythonology.Post navigationPrevious\\nPreviousTinyDB: A Lightweight Python Database for Simple ProjectsNextContinue\\na RAG Web Scraper with LangChain and OllamaSimilar Posts\\n\\nPython Library | Python Skills | Web Scraping A Beginner’s Guide to Using the LXML Library in Python\\n\\nRead More A Beginner’s Guide to Using the LXML Library in PythonContinue\\n \\n\\nPython Library | web development Reflex: React With Python!\\n\\nRead More Reflex: React With Python!Continue\\n \\n\\nPython Library | Python Skills Cleaner, More Reliable Python Code with Type Hints in python\\n\\nRead More Cleaner, More Reliable Python Code with Type Hints in pythonContinue\\n \\n\\nPython Library GLOB Module: File Searching in Python\\n\\nRead More GLOB Module: File Searching in PythonContinue\\n \\n\\nPython Library TinyDB: A Lightweight Python Database for Simple Projects\\n\\nRead More TinyDB: A Lightweight Python Database for Simple ProjectsContinue\\n \\n\\nPython Library What is the best Python PDF library?\\n\\nRead More What is the best Python PDF library?Continue\\n \")]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import bs4\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "\n",
    "bs4_strainer = bs4.SoupStrainer(class_=(\"content-area\"))\n",
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://pythonology.eu/using-pandas_ta-to-generate-technical-indicators-and-signals/\",),\n",
    "    bs_kwargs={\"parse_only\": bs4_strainer},\n",
    ")\n",
    "docs = loader.load()\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain-text-splitters in .\\.venv\\lib\\site-packages (0.3.7)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in .\\.venv\\lib\\site-packages (from langchain-text-splitters) (0.3.48)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (0.3.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (4.12.2)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (2.10.6)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (3.10.16)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in .\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (2.27.2)\n",
      "Requirement already satisfied: anyio in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (4.9.0)\n",
      "Requirement already satisfied: certifi in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (1.0.7)\n",
      "Requirement already satisfied: idna in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (0.14.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (2.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in .\\.venv\\lib\\site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.45->langchain-text-splitters) (1.3.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-text-splitters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200, chunk_overlap=100, add_start_index=True\n",
    ")\n",
    "all_splits = text_splitter.split_documents(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-chroma\n",
      "  Using cached langchain_chroma-0.2.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "Requirement already satisfied: langchain-core!=0.3.0,!=0.3.1,!=0.3.10,!=0.3.11,!=0.3.12,!=0.3.13,!=0.3.14,!=0.3.2,!=0.3.3,!=0.3.4,!=0.3.5,!=0.3.6,!=0.3.7,!=0.3.8,!=0.3.9,<0.4.0,>=0.2.43 in .\\.venv\\lib\\site-packages (from langchain-chroma) (0.3.48)\n",
      "Collecting numpy<2.0.0,>=1.26.2 (from langchain-chroma)\n",
      "  Downloading numpy-1.26.4.tar.gz (15.8 MB)\n",
      "     ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "     - -------------------------------------- 0.5/15.8 MB 2.5 MB/s eta 0:00:07\n",
      "     -- ------------------------------------- 1.0/15.8 MB 2.8 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 1.8/15.8 MB 2.8 MB/s eta 0:00:06\n",
      "     ---- ----------------------------------- 1.8/15.8 MB 2.8 MB/s eta 0:00:06\n",
      "     ----- ---------------------------------- 2.4/15.8 MB 2.2 MB/s eta 0:00:07\n",
      "     ------ --------------------------------- 2.6/15.8 MB 2.1 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 2.9/15.8 MB 2.0 MB/s eta 0:00:07\n",
      "     ------- -------------------------------- 3.1/15.8 MB 2.0 MB/s eta 0:00:07\n",
      "     -------- ------------------------------- 3.4/15.8 MB 1.8 MB/s eta 0:00:08\n",
      "     --------- ------------------------------ 3.7/15.8 MB 1.7 MB/s eta 0:00:08\n",
      "     ---------- ----------------------------- 4.2/15.8 MB 1.8 MB/s eta 0:00:07\n",
      "     ------------ --------------------------- 5.0/15.8 MB 2.0 MB/s eta 0:00:06\n",
      "     -------------- ------------------------- 5.8/15.8 MB 2.1 MB/s eta 0:00:05\n",
      "     --------------- ------------------------ 6.3/15.8 MB 2.2 MB/s eta 0:00:05\n",
      "     ----------------- ---------------------- 7.1/15.8 MB 2.3 MB/s eta 0:00:04\n",
      "     ------------------- -------------------- 7.9/15.8 MB 2.4 MB/s eta 0:00:04\n",
      "     ---------------------- ----------------- 8.9/15.8 MB 2.5 MB/s eta 0:00:03\n",
      "     ----------------------- ---------------- 9.4/15.8 MB 2.5 MB/s eta 0:00:03\n",
      "     ------------------------- -------------- 10.2/15.8 MB 2.6 MB/s eta 0:00:03\n",
      "     --------------------------- ------------ 11.0/15.8 MB 2.7 MB/s eta 0:00:02\n",
      "     ------------------------------ --------- 12.1/15.8 MB 2.7 MB/s eta 0:00:02\n",
      "     -------------------------------- ------- 12.8/15.8 MB 2.8 MB/s eta 0:00:02\n",
      "     ---------------------------------- ----- 13.6/15.8 MB 2.8 MB/s eta 0:00:01\n",
      "     ------------------------------------ --- 14.4/15.8 MB 2.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------  15.5/15.8 MB 3.0 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 15.8/15.8 MB 3.0 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Installing backend dependencies: started\n",
      "  Installing backend dependencies: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'error'\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Preparing metadata (pyproject.toml) did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [19 lines of output]\n",
      "      + e:\\projects\\llm\\.venv\\Scripts\\python.exe C:\\Users\\Rishi Kumar\\AppData\\Local\\Temp\\pip-install-lpxf5oti\\numpy_aede3c15cbef4f19b4e1b15a9d77cc72\\vendored-meson\\meson\\meson.py setup C:\\Users\\Rishi Kumar\\AppData\\Local\\Temp\\pip-install-lpxf5oti\\numpy_aede3c15cbef4f19b4e1b15a9d77cc72 C:\\Users\\Rishi Kumar\\AppData\\Local\\Temp\\pip-install-lpxf5oti\\numpy_aede3c15cbef4f19b4e1b15a9d77cc72\\.mesonpy-56istzxl -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=C:\\Users\\Rishi Kumar\\AppData\\Local\\Temp\\pip-install-lpxf5oti\\numpy_aede3c15cbef4f19b4e1b15a9d77cc72\\.mesonpy-56istzxl\\meson-python-native-file.ini\n",
      "      The Meson build system\n",
      "      Version: 1.2.99\n",
      "      Source dir: C:\\Users\\Rishi Kumar\\AppData\\Local\\Temp\\pip-install-lpxf5oti\\numpy_aede3c15cbef4f19b4e1b15a9d77cc72\n",
      "      Build dir: C:\\Users\\Rishi Kumar\\AppData\\Local\\Temp\\pip-install-lpxf5oti\\numpy_aede3c15cbef4f19b4e1b15a9d77cc72\\.mesonpy-56istzxl\n",
      "      Build type: native build\n",
      "      Project name: NumPy\n",
      "      Project version: 1.26.4\n",
      "      C compiler for the host machine: gcc (gcc 6.3.0 \"gcc (MinGW.org GCC-6.3.0-1) 6.3.0\")\n",
      "      C linker for the host machine: gcc ld.bfd 2.28\n",
      "      C++ compiler for the host machine: c++ (gcc 6.3.0 \"c++ (MinGW.org GCC-6.3.0-1) 6.3.0\")\n",
      "      C++ linker for the host machine: c++ ld.bfd 2.28\n",
      "      Cython compiler for the host machine: cython (cython 3.0.12)\n",
      "      Host machine cpu family: x86\n",
      "      Host machine cpu: x86\n",
      "      \n",
      "      ..\\meson.build:28:4: ERROR: Problem encountered: NumPy requires GCC >= 8.4\n",
      "      \n",
      "      A full log can be found at C:\\Users\\Rishi Kumar\\AppData\\Local\\Temp\\pip-install-lpxf5oti\\numpy_aede3c15cbef4f19b4e1b15a9d77cc72\\.mesonpy-56istzxl\\meson-logs\\meson-log.txt\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: metadata-generation-failed\n",
      "\n",
      "× Encountered error while generating package metadata.\n",
      "╰─> See above for output.\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for details.\n"
     ]
    }
   ],
   "source": [
    "pip install langchain-chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.0\n"
     ]
    }
   ],
   "source": [
    "import langchain_ollama\n",
    "print(langchain_ollama.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import OllamaEmbeddings\n",
    "\n",
    "local_embeddings = OllamaEmbeddings(model=\"all-minilm\")  # Ensure the model name is a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1200,  # Corrected from max_chars\n",
    "    chunk_overlap=100,  # Corrected from min_chars\n",
    "    add_start_index=True,\n",
    ")\n",
    "\n",
    "# Assuming `docs` is a list of Document objects\n",
    "all_splits = text_splitter.split_documents(docs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(\n",
    "    documents=all_splits,  \n",
    "    embedding=local_embeddings,  # Corrected from \"embeddings\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what are the oversold and overbought periods?\"\n",
    "retriever = vectorstore.as_retriever(search_type=\"similarity\", search_kwargs={\"k\": 3})\n",
    "retrieved_docs = retriever.invoke(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "context = ' '.join([doc.page_content for doc in retrieved_docs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"llama3.2:1b\")\n",
    "response = llm.invoke(f\"\"\"Answer the question according to the context given very briefly:\n",
    "           Question: {question}.\n",
    "           Context: {context}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The oversold and overbought periods in the given data are:\\n\\n* Overbought: above 70 (Relative Strength Index)\\n* Oversold: below 30 (Relative Strength Index)'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
